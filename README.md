# SparseCNNs

Abstract
本文主要研究了稀疏输入下的卷积神经网络，并用稀疏的激光雷达扫描数据进行实验。传统的CNN在输入稀疏数据时性能很差，即使提供了丢失数据的位置，效果也不理想。为了解决这个问题，本文提出了一个简单有效的稀疏卷积层，在卷积运算中明确考虑了丢失数据的位置。

1.Introduction

卷积神经网络CNN几乎影响了计算机视觉的所有领域。通常情况下，CNN的输入是一个图像或者视频，用稠密的矩阵或者张量表示。通过将卷积层与非线性层、池化层结合，CNN能够在第一层提取低层次特征，然后再后续层中依次学习更高层次的特征。然而，当网络的输入是稀疏或者不规则的（例如只有10%的像素携带有用信息），对于每个滤波器的位置该怎样定义不十分明确，输入的数量和位置会发生变化。

为了解决这个问题，一个简单的方法是给所有无信息的位置分配一个默认值，但是这种方法只能得到次优的结果，因为过滤器必须对所有可能的激活模式保持不变，其数量随着过滤器的尺寸呈指数增长。

本文提出了一个简单有效的解决方案：引入了一个稀疏的卷积层，它根据输入像素的有效性对卷积核的元素进行加权。此外，第二个stream将关于像素有效性的信息传送给网络的后续层。

重要的是，实验证明，该网络对不同稀疏程度的输入数据都有很好的效果，训练数据和测试数据的稀疏程度不同，并不会使结果变差。

本文提出的另一种方法是将激光扫描投影到虚拟或者真实的2D图像平面上，从而产生2.5D的特征表示。处理可以将深度图建模为二维回归问题之外，这种表示还可以集成更多的密集信息（例如来自彩色相机的RGB值）。但是，投影激光扫描通常非常稀疏，不能保证与常规像素网格对齐，因此在使用标准CNN处理时效果不佳。相反，本文所提出的的方法，即使输入是稀疏和不规则的，也能产生很好的结果。

2.Related Work

CNN with Sparse Inputs:处理稀疏输入的简单方法是将无效值赋值0或者为编码每个像素有效性的网络创建额外的输入通道。

Sparsity in CNNs：主要着眼于通过利用网络的稀疏性来提高神经网络的效率，但并不能解决稀疏输入的问题。

Invariant Representations：提高模型对输入变化的稳健性是计算机视觉的长期目标。在本文中，学习表示的问题应该对输入的稀疏程度是不变的。实验证明，即使训练数据和测试数据的稀疏水平显著不同，模型也表现良好。这具有重要的意义，意味着可以将激光扫描仪换成其他传感器而不需要重新训练网络。

Depth Upsampling：需要直接输入深度或者其他来自高分辨率图像的监督。



